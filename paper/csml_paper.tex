% CSML Final Project Paper

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2019}
\usepackage{times}
\usepackage{latexsym}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{float}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{pgfplots}
\usepackage{svg}
\usepackage[inline]{enumitem}
\pgfplotsset{compat=newest}
\usetikzlibrary{fit,backgrounds,positioning}
\usepackage{url}

\aclfinalcopy % Uncomment this line for the final submission

\newcommand\BibTeX{B\textsc{ib}\TeX}

\everydisplay{\small}

\title{Yahtzee: Reinforcement Learning Techniques for Stochastic Combinatorial Games}

\author{Nicholas Pape \\
  nap626 \\
  \texttt{nickpape@utexas.edu} \\}

\date{2025-12-01}

\begin{document}
\maketitle
\begin{abstract}
  Yahtzee is a classic dice game whose stochastic, combinatorial structure and delayed rewards make it an interesting mid-scale RL benchmark.
  While an optimal policy for solitaire Yahtzee can be computed using dynamic programming methods, multiplayer is intractable, motivating approximation methods.
  We formulate Yahtzee as a Markov Decision Process (MDP), and train self-play agents using various policy gradient methods:
  REINFORCE, Advantage Actor-Critic (A2C), and Proximal Policy Optimization (PPO), all using a multi-headed network with a shared trunk.
  We ablate feature encodings, architecture, return estimators, reward shaping, and entropy regularization.

  Under a fixed training budget, REINFORCE and PPO prove sensitive to hyperparameters and fail to reach near-optimal performance,
  whereas A2C trains robustly across a range of settings. Our agent attains a median score of <242.5> points over 10,000 games,
  within <4.7\%> of the optimal DP score of 254.59, achieving the upper section bonus and Yahtzee at rates of <X>\% and <Y>\%, respectively.
  All models struggle to learn the upper bonus strategy, overindexing on four-of-a-kind's, highlighting persistent long-horizon credit-assignment
  and exploration challenges.
\end{abstract}

\input{1_introduction}
\input{2_related_work}
\input{3_problem_formulation}
\input{4_methodology}
\input{5_results}
\input{6_discussion}
\input{7_conclusion}

\bibliographystyle{acl_natbib}
\bibliography{csml_bibliography}

\clearpage
\input{8_appendix}

\end{document}
