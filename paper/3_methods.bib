% ============================================================================
% 3. METHODS
% ============================================================================
% This is where you get to be citation-dense without bloating the prose.

% ----------------------------------------------------------------------------
% 3.1 Environment / Game Definition
% ----------------------------------------------------------------------------

% NOTE: The following are already defined in 1_introduction.bib:
% hasbro-2022-yahtzee-rules
% glenn-2006-optimal-yahtzee
% pawlewicz-2011-multiplayer-yahtzee

% ----------------------------------------------------------------------------
% 3.2 Architecture (state representation, activations, init, attention)
% ----------------------------------------------------------------------------

% Capacity / width choices (already defined in 1_introduction.bib):
% horne-1994-bounds-rnn-fsm
% hanin-2017-bounded-width-relu

% Layer Normalization
@article{ba-2016-layernorm,
  author  = {Jimmy Lei Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
  title   = {Layer Normalization},
  journal = {arXiv preprint arXiv:1607.06450},
  year    = {2016}
}

% Kaiming/He initialization for ReLU networks
@inproceedings{he-2015-delving-rectifiers,
  author    = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  title     = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year      = {2015},
  pages     = {1026--1034},
  doi       = {10.1109/ICCV.2015.123}
}

% Swish activation function
@article{ramachandran-2017-swish,
  author  = {Prajit Ramachandran and Barret Zoph and Quoc V. Le},
  title   = {Searching for Activation Functions},
  journal = {arXiv preprint arXiv:1710.05941},
  year    = {2017}
}

% SiLU (Sigmoid-Weighted Linear Units) activation for RL
@article{elfwing-2018-silu-rl,
  author  = {Stefan Elfwing and Eiji Uchibe and Kenji Doya},
  title   = {Sigmoid-Weighted Linear Units for Neural Network Function Approximation in Reinforcement Learning},
  journal = {Neural Networks},
  year    = {2018},
  volume  = {107},
  pages   = {3--11},
  doi     = {10.1016/j.neunet.2017.12.012}
}

% GELU activation
@article{hendrycks-2016-gelu,
  author  = {Hendrycks, Dan and Gimpel, Kevin},
  title   = {Gaussian Error Linear Units (GELUs)},
  journal = {arXiv preprint arXiv:1606.08415},
  year    = {2016},
  url     = {https://arxiv.org/abs/1606.08415}
}

% RAdam optimizer (variance of adaptive learning rate)
@article{liu-2019-radam,
  title         = {On the Variance of the Adaptive Learning Rate and Beyond},
  author        = {Liu, Liyuan and Jiang, Haoming and He, Pengcheng and Chen, Weizhu and Liu, Xiaodong and Gao, Jianfeng and Han, Jiawei},
  journal       = {arXiv preprint arXiv:1908.03265},
  year          = {2019},
  eprint        = {1908.03265},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1908.03265}
}

% Attention mechanism
@inproceedings{vaswani-2017-attention,
  title     = {Attention {I}s {A}ll {Y}ou {N}eed},
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob
               and Jones, Llion and Gomez, Aidan N. and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R.
               and Vishwanathan, S. and Garnett, R.},
  volume    = {30},
  year      = {2017}
}

% ----------------------------------------------------------------------------
% 3.3 RL Algorithms & Optimization (REINFORCE / A2C / PPO / tricks)
% ----------------------------------------------------------------------------

% Core algorithm references (already defined in 2_related_work.bib):
% sutton-2018-reinforcement-book
% williams-1992-reinforce
% sutton-1988-temporal-differences
% sutton-2000-policy-gradient
% mnih-2016-a3c
% schulman-2016-gae
% schulman-2017-ppo
% greensmith-2004-variance-reduction

% Gradient clipping for RNN stability
@article{pascanu-2013-rnn-clipping,
  author  = {Razvan Pascanu and Tomas Mikolov and Yoshua Bengio},
  title   = {On the Difficulty of Training Recurrent Neural Networks},
  journal = {arXiv preprint arXiv:1211.5063},
  year    = {2013}
}

% bjorck-2022-high-variance - already defined in 2_related_work.bib

% Normalization and effective learning rates in RL
@article{lyle-2024-normalization-rl,
  title         = {Normalization and effective learning rates in reinforcement learning},
  author        = {Lyle, Clare and Zheng, Zeyu and Khetarpal, Khimya and Martens, James and van Hasselt, Hado and Pascanu, Razvan and Dabney, Will},
  journal       = {arXiv preprint arXiv:2407.01800},
  year          = {2024},
  eprint        = {2407.01800},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2407.01800}
}

% Learning rate warmup mechanisms
@article{kalra-2024-warmup,
  title         = {Why Warmup the Learning Rate? Underlying Mechanisms and Improvements},
  author        = {Kalra, Dayal Singh and Barkeshli, Maissam},
  journal       = {arXiv preprint arXiv:2406.09405},
  year          = {2024},
  eprint        = {2406.09405},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2406.09405}
}

% Theoretical analysis of learning rate warmup
@article{liu-2025-warmup-theory,
  title         = {Theoretical Analysis on how Learning Rate Warmup Accelerates Convergence},
  author        = {Liu, Yuxing and Ge, Yuze and Pan, Rui and Kang, An and Zhang, Tong},
  journal       = {arXiv preprint arXiv:2509.07972},
  year          = {2025},
  eprint        = {2509.07972},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2509.07972}
}

% 
@article{mazyavkina2021rl_co_survey,
  title   = {Reinforcement Learning for Combinatorial Optimization: A Survey},
  author  = {Mazyavkina, Nina and Sviridov, Sergey and Ivanov, Sergei and Burnaev, Evgeny},
  journal = {Computers \& Operations Research},
  volume  = {134},
  pages   = {105400},
  year    = {2021},
  doi     = {10.1016/j.cor.2021.105400}
}

% KL-aware Policy Optimization Baselines (IMPALA, TRPO)
@article{espeholt2018impala,
  title   = {{IMPALA}: Scalable Distributed Deep-{RL} with Importance Weighted Actor-Learner Architectures},
  author  = {Espeholt, Lasse and Soyer, Hubert and Munos, R{\'e}mi and Simonyan, Karen
             and Mnih, Volodymyr and Ward, Tom and Doron, Yotam and Firoiu, Vlad
             and Harley, Tim and Dunning, Matthew and others},
  journal = {arXiv preprint arXiv:1802.01561},
  year    = {2018}
}

@inproceedings{schulman2015trpo,
  title     = {Trust Region Policy Optimization},
  author    = {Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
  pages     = {1889--1897},
  year      = {2015}
}

% =========================================================
% Regularization: Dropout, ELU, Warmup (Goyal)
% =========================================================

@article{srivastava2014dropout,
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  author  = {Srivastava, Nitish and Hinton, Geoffrey E. and Krizhevsky, Alex
             and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal = {Journal of Machine Learning Research},
  volume  = {15},
  number  = {56},
  pages   = {1929--1958},
  year    = {2014}
}

@inproceedings{clevert2016elu,
  title     = {Fast and Accurate Deep Network Learning by Exponential Linear Units ({ELUs})},
  author    = {Clevert, Djork-Arn{\'e} and Unterthiner, Thomas and Hochreiter, Sepp},
  booktitle = {Proceedings of the International Conference on Learning Representations},
  year      = {2016},
  note      = {arXiv:1511.07289}
}

@article{goyal2017imagenet1hour,
  title   = {Accurate, Large Minibatch {SGD}: Training {ImageNet} in 1 Hour},
  author  = {Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter
             and Wesolowski, Lukasz and Kyrola, Aleksi and Tulloch, Andrew
             and Jia, Yangqing and He, Kaiming},
  journal = {arXiv preprint arXiv:1706.02677},
  year    = {2017}
}

% =========================================================
% Factored / Branching Action Spaces, Multi-Head Policies
% (Tavakoli action branching + Stone parameterized actions)
% =========================================================

@inproceedings{tavakoli2018actionbranching,
  title     = {Action Branching Architectures for Deep Reinforcement Learning},
  author    = {Tavakoli, Arash and Pardo, Fabio and Kormushev, Petar},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {32},
  number    = {1},
  year      = {2018}
}

@inproceedings{hausknecht2016parameterized,
  title     = {Deep Reinforcement Learning in Parameterized Action Space},
  author    = {Hausknecht, Matthew and Stone, Peter},
  booktitle = {Proceedings of the International Conference on Learning Representations (Workshop Track)},
  year      = {2016},
  note      = {arXiv:1511.04143}
}


% =========================================================
% Entropy Bonus / Penalty in RL
% (policy entropy as regularizer, max-ent RL)
% =========================================================

@inproceedings{ahmed2019entropy,
  title     = {Understanding the Impact of Entropy on Policy Optimization},
  author    = {Ahmed, Zafarali and Le Roux, Nicolas and Norouzi, Mohammad and Schuurmans, Dale},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  series    = {Proceedings of Machine Learning Research},
  volume    = {97},
  pages     = {151--160},
  publisher = {PMLR},
  year      = {2019}
}

@inproceedings{haarnoja2018sac,
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author    = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning},
  series    = {Proceedings of Machine Learning Research},
  volume    = {80},
  pages     = {1861--1870},
  publisher = {PMLR},
  year      = {2018}
}

% adds entropy to REINFORCE
@article{williams-peng-1991-function-optimization,
  author  = {Williams, Ronald J. and Peng, Jing},
  title   = {Function Optimization using Connectionist Reinforcement Learning Algorithms},
  journal = {Connection Science},
  volume  = {3},
  number  = {3},
  pages   = {241--268},
  year    = {1991},
  doi     = {10.1080/09540099108946587},
  url     = {https://doi.org/10.1080/09540099108946587}
}


% =========================================================
% Temperature / Softmax Sampling in RL / Bandits
% =========================================================

@inproceedings{tijsma2016comparing_exploration,
  title     = {Comparing Exploration Strategies for {Q}-Learning in Random Stochastic Mazes},
  author    = {Tijsma, Arryon and Drugan, Madalina M. and Wiering, Marco A.},
  booktitle = {2016 IEEE Symposium Series on Computational Intelligence (SSCI)},
  pages     = {1--8},
  year      = {2016},
  publisher = {IEEE}
}

@inproceedings{cesa-bianchi2017boltzmann,
  title     = {Boltzmann Exploration Done Right},
  author    = {Cesa-Bianchi, Nicol{\`o} and Gentile, Claudio and Lugosi, G{\'a}bor and Neu, Gergely},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {30},
  year      = {2017}
}


% =========================================================
% Frameworks / Tooling: Gym, PyTorch, Lightning, W&B
% =========================================================

% brockman2016openai - already defined in 1_introduction.bib

@inproceedings{paszke2019pytorch,
  title     = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author    = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam
               and Bradbury, James and Chanan, Gregory and Killeen, Trevor
               and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca
               and Desmaison, Alban and Kopf, Andreas and Yang, Edward
               and DeVito, Zachary and Raison, Martin and Tejani, Alykhan
               and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu
               and Bai, Junjie and Chintala, Soumith},
  booktitle = {Advances in Neural Information Processing Systems 32},
  year      = {2019}
}

@article{falcon2019pytorchlightning,
  title        = {{PyTorch Lightning}},
  author       = {Falcon, William A.},
  journal      = {GitHub repository},
  year         = {2019},
  howpublished = {\url{https://github.com/Lightning-AI/lightning}}
}

@misc{biewald2020wandb,
  author       = {Biewald, Lukas},
  title        = {Experiment Tracking with Weights and Biases},
  year         = {2020},
  howpublished = {\url{https://www.wandb.com/}},
  note         = {Software available from wandb.com}
}