# ğŸ² Learning to Play Yahtzee with Reinforcement Learning

> **Final Project** | *Case Studies in Machine Learning* | UT Austin MS in Artificial Intelligence


## ğŸ“„ Read the Paper
**The complete research paper with full technical details, experiments, and results:**
> ### **[ğŸ“– View Paper (PDF)](./paper/csml_paper.pdf)**


## ğŸ¯ Project Overview

This project explores how well reinforcement learning agents can master Yahtzee through **pure RL training** â€” without hand-crafted strategies or game-specific heuristics. We investigate two key approaches:

### ğŸ”¹ Single-Turn Learning
Training agents to maximize score on **individual turns** (roll â†’ roll â†’ roll â†’ score), then evaluating how well this generalizes to full games.

### ğŸ”¹ Full-Game Learning  
Training agents to play **complete 13-round games**, learning long-term strategy and category selection across an entire game.

---

## ğŸš€ Quick Start

### Run Single-Turn RL Training
```bash
./single_turn_rl.sh
```

Trains an agent on isolated single-turn gameplay. The agent learns optimal dice-keeping and scoring strategies for maximizing points in a single turn.

### Run Full-Game RL Training
```bash
./full_game_rl.sh
```

Trains an agent to play complete Yahtzee games. The agent must learn strategic category selection, timing, and trade-offs across all 13 turns.

---

## ğŸ“Š Performance Overview

| Approach | Average Score | Key Insight |
|----------|---------------|-------------|
| **Random Policy** | ~49 | Baseline performance |
| **One-turn Expectimax** | ~110 | Greedy single-turn expectimax |
| **Single-Turn REINFORCE** | ~200 | Strong tactical decisions |
| **Full-Game REINFORCE** | ~180-200 | Strategic category planning |
| **One-turn Expectimax (Optimal)** | ~254 | Theoretical upper bound |

---

## ğŸ—ï¸ What's in the repo?

- âœ… Custom Yahtzee environment following OpenAI Gym interface
- âœ… REINFORCE policy gradient implementation with PyTorch Lightning
- âœ… Single-turn and full-game training pipelines
- âœ… Expectimax baseline for performance comparison
- âœ… Comprehensive evaluation framework
- âœ… W&B integration for experiment tracking

---

## ğŸ“š Repository Structure

```
â”œâ”€â”€ paper/              # LaTeX source and compiled PDF
â”œâ”€â”€ src/                # All source code
â”‚   â”œâ”€â”€ environments/   # Yahtzee gym environment
â”‚   â”œâ”€â”€ yahtzee_agent/  # RL agent implementations
â”‚   â””â”€â”€ utilities/      # Helper functions and baselines
â”œâ”€â”€ checkpoints/        # Trained model checkpoints
â””â”€â”€ logs/              # Training logs and metrics
```

---

## ğŸ“ About

This work was completed as the final project for the **Case Studies in Machine Learning** course in the University of Texas at Austin's Master of Science in Artificial Intelligence program.

**For full details on methodology, architecture, experiments, and analysis, please see the [paper](./paper/csml_paper.pdf).**